{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, let's import spaCy and the create_object script.  This includes as `create_object()` function that will generate a generic language object in the folder `new_lang/{language_name}`.  All of the object's files are contained there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.6'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install needed util files if missing\n",
    "import spacy \n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    !mkdir util\n",
    "    !wget -O /content/util/corpus.py https://raw.githubusercontent.com/New-Languages-for-NLP/cadet-the-notebook/main/util/corpus.py\n",
    "    !wget -O /content/util/create_object.py https://raw.githubusercontent.com/New-Languages-for-NLP/cadet-the-notebook/main/util/create_object.py\n",
    "    !wget -O /content/util/export.py https://raw.githubusercontent.com/New-Languages-for-NLP/cadet-the-notebook/main/util/export.py\n",
    "    !wget -O /content/util/tokenization.py https://raw.githubusercontent.com/New-Languages-for-NLP/cadet-the-notebook/main/util/tokenization.py\n",
    "    #colab currently uses spacy 2.2.4, need 3\n",
    "    if '3' not in spacy.__version__[:1]:\n",
    "        !pip install spacy --upgrade\n",
    "\n",
    "import spacy\n",
    "from util.create_object import create_object\n",
    "spacy.__version__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_name = 'Yiddish'\n",
    "lang_code ='yi'\n",
    "direction = 'rtl'\n",
    "has_case = False\n",
    "has_letters = True\n",
    "\n",
    "# create_object(lang_name, lang_code, direction, has_case, has_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py             \u001b[34mlookups\u001b[m\u001b[m                 tag_map.py\r\n",
      "base_config.cfg         punctuation.py          \u001b[34mtexts\u001b[m\u001b[m\r\n",
      "examples.py             setup.py                tokenizer_exceptions.py\r\n",
      "lemmatizer.py           stop_words.py           \u001b[34myi.egg-info\u001b[m\u001b[m\r\n",
      "lex_attrs.py            syntax_iterators.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./new_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess how the tokenizer defaults will work with your language, add example sentences to the [`examples.py`](./new_lang/examples.py) file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><span style='border: 5px solid blue; margin:5px;'>זינגט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אלץ</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>נאך</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>מיין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>ווארט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>.</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>כ׳לעבן</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>,</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>ס׳</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>איז</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>געווען</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>א</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>העזה</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>.</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>איך</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>וווין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>תל־אביב</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>און</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דו</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>?</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>צי</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>האסט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>ו</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>היינט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>א</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>שטיקל</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>צייט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>?</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>איך</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>בין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>זיכער</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>,</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אז</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דארפסט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>ו</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דארט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>גיין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אליין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>!</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>וואס</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>איז</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אזוי</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>שיין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דאס</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>בוך</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>?</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>אויפ</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>ן</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>וועג</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>שטייט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>א</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>בוים</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>.</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>איך</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>האב</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דאס</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>געליינט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אינ</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>עם</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>בוך</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>.</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>צוריקוועגס</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>,</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>האט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>א</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>פייגנבוים</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>פארשטעלט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>.</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>און</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דערנאך</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>באשיטן</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>מיט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>זאלץ</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>-</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>האבן</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אנדערע</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>צוגעגעבן</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>.</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>אזוי</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>איז</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>,</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>חבר</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>קאמאנדיר</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>,</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>-</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>נאט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דער</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>רויט־בערדיקער</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>פויער</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>געענטפערט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>און</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>געשוויגן</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>א</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>צייט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>.</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>אין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>זיין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אויפגעשרויפטער</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דערווארטונג</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>האט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>ער</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>פארגעסן</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>יעדער</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>נויט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>און</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>הונגער</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>,</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אפילו</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דער</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>היים</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דער</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אייגענער</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>.</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>יונג</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>זיינען</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>די</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>קינדער</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דעם</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אלטן</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>לאנד</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>.</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>די</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>טיר</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>איז</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אפן</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>,</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>און</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>איך</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>ווייס</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>:</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דו</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>ביסט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אריין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>.</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>ער</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>וויל</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>ניט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>פארשרייבן</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>זיין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>זוך</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דאס</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>שול</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>.</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>זי</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>שיקט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אריין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>זיין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>בריוו</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>.</span>&nbsp;</div><div><span style='border: 5px solid blue; margin:5px;'>איך</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>וויל</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>נישט</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>דאס</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אריינשיקן</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>אין</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>גאנצן</span>&nbsp;<span style='border: 5px solid blue; margin:5px;'>!</span>&nbsp;</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "from util.tokenization import tokenization\n",
    "HTML(tokenization(lang_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To adjust the tokenizer you can add unique exceptions or regular exceptions to the [tokenizer_exceptions.py](./new_lang/tokenizer_exceptions.py) file\n",
    "\n",
    "- To join two tokens, add an exception `{'BIG YIKES':[{ORTH: 'BIG YIKES'}]}`\n",
    "- To split a token in two, `{'Kummerspeck':[{ORTH:\"Kummer\"},{ORTH:\"speck\"}]}`\n",
    "\n",
    "Note in both cases that we add a dictionary. The key is the string to match on, with a list of tokens.  In the first case we had a single token where we would otherwise have two and vice versa. You can find more details in the spaCy documentation and [here](https://new-languages-for-nlp.github.io/course-materials/w1/tokenization.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookups \n",
    "\n",
    "The `create_object()` function creates a `new_lang/lookups` directory that contains three files.  These are simple json lookups for unambiguous pos, lemma and features. You can add your data to these files and automatically update token values.  Keep in mind that you'll need to find a balance between the convenience of automatically annotating tokens and the inconvenience of having to correct machine errors.  Once you're done updating the files with your existing linguistic data, proceed to the next step. \n",
    "\n",
    "https://universaldependencies.org/u/pos/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texts\n",
    "\n",
    "For us to identify frequent tokens for automatic annotation, you'll need to provide texts.  Place your machine-readable utf-8 text files in the `new_lang/texts` folder.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'texts': 1928, 'tokens': 8186502, 'unique_tokens': 111897}\n"
     ]
    }
   ],
   "source": [
    "from util.corpus import make_corpus\n",
    "\n",
    "# https://www.online-toolz.com/tools/text-unicode-entities-convertor.php\n",
    "make_corpus(lang_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of make_corpus is a json file at [`new_lang/corpus_json/tokens.json`](./new_lang/corpus_json/tokens.json). For each token, you'll find a `text` key for the token's string as well as keys for pos_, lemma_ and ent_type_. Keep in mind that this system is not able to process ambiguous lookups.  Only enter data for tokens or spans with very little semantic variation.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🍉 To bulk annotate 33% of the corpus, add data to first 20 tokens\n",
      "🍅 To bulk annotate 50% of the corpus, add data to first 57 tokens\n",
      "🍒 To bulk annotate 66% of the corpus, add data to first 263 tokens\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import srsly\n",
    "from pathlib import Path \n",
    "\n",
    "def get_percentages():\n",
    "    thirds = []\n",
    "    halfs = []\n",
    "    two_thirds = [] \n",
    "    tokens = srsly.read_json(Path.cwd() / 'new_lang' / 'corpus_json' / 'tokens.json')\n",
    "    tokens = srsly.json_loads(tokens)\n",
    "    for token in tokens:\n",
    "        if token['rank'] == 1:\n",
    "            total_tokens = token['count'] + token['remain']\n",
    "        \n",
    "        percent_annotated = 1 - (token['remain'] / total_tokens)\n",
    "        percent_annotated = int((percent_annotated * 100))\n",
    "        if percent_annotated == 33:\n",
    "            thirds.append(token)\n",
    "        if percent_annotated == 50:\n",
    "            halfs.append(token)\n",
    "        if percent_annotated == 66:\n",
    "            two_thirds.append(token)\n",
    "    return thirds[0], halfs[0], two_thirds[0]\n",
    "        \n",
    "    #let percent_annotated = 1 - (token.remain / total_tokens);\n",
    "#    let percent_annotated_str = (percent_annotated*100).toFixed(0);\n",
    "third, half, two_thirds = get_percentages()\n",
    "print(f\"\"\"\n",
    "🍉 To bulk annotate 33% of the corpus, add data to first {third['rank']} tokens\n",
    "🍅 To bulk annotate 50% of the corpus, add data to first {half['rank']} tokens\n",
    "🍒 To bulk annotate 66% of the corpus, add data to first {two_thirds['rank']} tokens\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will export your texts and lookups in a TSV file in the CoreNLP format.  This data can then be loaded into INCEpTION for annotation work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HTTPException' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/berkotech/PrincetonNLPYiddish/research/cadet-notebook/util/export.py\u001b[0m in \u001b[0;36mupdate_tokens_with_lookups\u001b[0;34m(nlp, docs)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/spacy/tokens/token.pyx\u001b[0m in \u001b[0;36mspacy.tokens.token.Token.pos_.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ADJ.FEM.NOM.SG ADJ.NEUT.NOM/ACC.DEF.SG ADJ.PL'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e0b2127e945d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/berkotech/PrincetonNLPYiddish/research/cadet-notebook/util/export.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(lang_name)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"filename\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_tokens_with_lookups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mconllu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc_to_conllu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/berkotech/PrincetonNLPYiddish/research/cadet-notebook/util/export.py\u001b[0m in \u001b[0;36mupdate_tokens_with_lookups\u001b[0;34m(nlp, docs)\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                     raise HTTPException(\n\u001b[0m\u001b[1;32m    163\u001b[0m                         \u001b[0mstatus_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Invalid part of speech type: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HTTPException' is not defined"
     ]
    }
   ],
   "source": [
    "from util.export import download\n",
    "\n",
    "download(lang_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have completed all annotation work in INCEpTION, you're ready to begin model training. This final step will export your spaCy language object. From there you can follow the spaCy documentation on model training!  \n",
    "\n",
    "1. package the object into a usable folder, that can be moved, and initialized using projects\n",
    "2. nlp.to_disk(\"/tmp/checkpoint\")?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spaCy project file for your project.  \n",
    "from util.project import make_project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created file /Users/ephraimb/berkotech/PrincetonNLPYiddish/research/cadet-notebook/Yiddish.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from util.project import make_project\n",
    "\n",
    "new_lang = Path.cwd() / \"new_lang\"\n",
    "make_project(lang_name,lang_code)\n",
    "\n",
    "#make export directory \n",
    "export_path = Path.cwd() / lang_name\n",
    "\n",
    "\n",
    "#shutil.make_archive(\"zipped_sample_directory\", \"zip\", \"sample_directory\")\n",
    "shutil.make_archive(str(export_path), 'zip', str(new_lang))\n",
    "zip_file = Path.cwd() / (lang_name + '.zip')\n",
    "print(f'created file {zip_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
